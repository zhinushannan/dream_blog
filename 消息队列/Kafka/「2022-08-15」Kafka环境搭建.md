```text
Kafka环境搭建
2022-08-15
消息队列>Kafka
https://picgo.kwcoder.club/202208/202208200937408.png
```

> 前提条件：[配置Zookeeper集群](/p/20220718/)

# Kafka下载与配置（以kafka_2.13-3.2.1为例）



官网下载：[https://kafka.apache.org/downloads](https://kafka.apache.org/downloads)

在`/etc/profile`中配置环境变了：

```shell
export KAFKA_HOME={安装的目录}
export PATH=$PATH:$KAFKA_HOME/bin
```

## 统一修改

在三台服务器上统一修改`$KAFKA_HOME/bin/kafka-server-start.sh`，在脚本正文的第一行添加`export JMX_PORT=9988`，用于获取资源等监控信息。

## `$KAFKA_HOME/conf/server.properties`

### master主机修改

- 修改`broker.id`的值为0
- 修改`listener`的值为`PLAINTEXT://[master_host]:9092`
- 修改`advertises.listeners`的值为`PLAINTEXT://[master_host]:9092`
- 修改`log.dirs`为自定义的目录，便于管理
- 修改`zookeeper.connect`的值为`[master_host]:2181,[slave1_host]:2181,[slave2_host]:2181`


### slave1主机修改

- 修改`broker.id`的值为1
- 修改`listener`的值为`PLAINTEXT://[slave1_host]:9092`
- 修改`advertises.listeners`的值为`PLAINTEXT://[slave1_host]:9092`
- 修改`log.dirs`为自定义的目录，便于管理
- 修改`zookeeper.connect`的值为`[master_host]:2181,[slave1_host]:2181,[slave2_host]:2181`


### slave2主机修改

- 修改`broker.id`的值为2
- 修改`listener`的值为`PLAINTEXT://[slave2_host]:9092`
- 修改`advertises.listeners`的值为`PLAINTEXT://[slave2_host]:9092`
- 修改`log.dirs`为自定义的目录，便于管理
- 修改`zookeeper.connect`的值为`[master_host]:2181,[slave1_host]:2181,[slave2_host]:2181`

## 编写一键启动和停止脚本

由于Kafka是集群形式的，因此需要在多台服务器上启动，可以通过一键启动脚本的方式简化操作。

一键启动脚本：

```shell
#!/bin/sh

echo "starting kafka serever......"

ssh master "source /etc/profile;kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties"

ssh slave1 "source /etc/profile;kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties"

ssh slave2 "source /etc/profile;kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties"

```

一键停止脚本：

```shell
#!/bin/sh

echo "stoping kafka serever......"

ssh master "source /etc/profile;kafka-server-stop.sh -daemon $KAFKA_HOME/config/server.properties"

ssh slave1 "source /etc/profile;kafka-server-stop.sh -daemon $KAFKA_HOME/config/server.properties"

ssh slave2 "source /etc/profile;kafka-server-stop.sh -daemon $KAFKA_HOME/config/server.properties"


```

将脚本放置在`$KAFKA_HOME/bin`下，并为脚本授权，可以方便脚本调用。
该脚本只需要放在一台主机上即可，通常习惯上放在`master`主机上。

执行`kafka-start-all.sh`启动集群，执行`kafka-stop-all.sh`停止集群。

# kafka-edge监控系统

## 下载

官网：[http://download.kafka-eagle.org/](http://download.kafka-eagle.org/)
选择`Direct File Download`按钮下载。

下载完成后将其上传至服务器并解压。


## 配置

### 配置环境变量

在`/etc/profile`添加：

```shell
export KE_HOME={监控系统所在的目录}
export PATH=$PATH:$KE_HOME/bin
```

### 修改`ke.sh`

在文件头部添加：

```shell
export JAVA_HOME={服务器上的JAVA_JAVA_HOME}
exprt KE_HOME={监控系统所在的目录}
```

将`KE_JAVA_OPTS`中的`-Xmx2g -Xms2g`修改为`-Xmx1g -Xms1g`

### 修改`system-config.properties`

将`cluster1.zk.list`的值修改为自己的主机，如`master:2181,slave1:2181,slave2:2181`，并将`cluster2.zk.list=xdn10:2181,xdn11:2181,xdn12:2181`注释掉。

将`cluster2.efak.offset.storage`注释掉。

将`cluster1.efak.sasl.enable`的值修改为`true`，修改`cluster1.efak.sasl.jaas.config`值中的`username`和`password`，为登录用户和密码。

将`kafka sqlite jdbc driver address`的配置的注释去掉并修改`efak.url`的值为`jdbc:sqlite:/$KE_HOME/db/ke.db。
将`kafka mysql jdbc driver address`的配置注释掉，并修改


## 执行

启动监控系统：`ke.sh start`
停止监控系统：`ke.sh stop`
查看监控系统状态：`ke.sh status`

# 常见bug解决

## 启动KAFKA：Error: VM option ‘UseG1GC‘ is experimental and must be enabled via -XX:+UnlockExperimental

找到`$KAFKA_HOME/bin/kafka-run-class.sh`，找到`KAFKA_JVM_PERFORMANCE_OPTS="-server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 ...`，将其中的`-XX:+UseG1GC `去掉。

注意：如果在启动Kafka时出现了这样的错误，这意味着在启动Kafka-edge时可能也会出现类似的错误。

## Kafka-edge启动后自动退出

请检查`$KE_HOME/kms/logs`下的日志文件，是否也有`-XX:+UseG1GC`相关的报错，如果有，则修改`$KE_HOME/bin/kw.sh`中的`KE_JAVA_OPTS`，去掉`-XX:+UseG1GC`。