```text
Kafka编程
2022-08-16
消息队列>Kafka
https://picgo.kwcoder.club/202208/202208200937408.png
```

# 命令行操作

## 主题操作

- 创建主题：`kafka-topics.sh --create --bootstrap-server [host]:9092 --replication-factor 1 --partitions 1 --topic [topic_name]`
- 查看主题列表：`kafka-topics.sh --bootstrap-server [host]:9092 --list`
- 查看主题详细信息：`kafka-topics.sh --bootstrap-server [host]:9092 --describe --topic [topic_name]`
- 删除主题：`kafka-topics.sh --bootstrap-server [host]:9092 --delete --topic [topic_name]`



```shell
[root@master opt]# kafka-topics.sh 
module/   work_dir/ 
[root@master opt]# kafka-topics.sh --create --bootstrap-server master:9092 --replication-factor 1 --partitions 1 --topic test
Created topic test.
[root@master opt]# kafka-topics.sh --bootstrap-server master:9092 --list
test
[root@master opt]# kafka-topics.sh --bootstrap-server master:9092 --describe --topic test
Topic: test	TopicId: fGXaTM2VQUKtuSfcj7u3gQ	PartitionCount: 1	ReplicationFactor: 1	Configs: segment.bytes=1073741824
	Topic: test	Partition: 0	Leader: 2	Replicas: 2	Isr: 2
[root@master opt]# kafka-topics.sh --bootstrap-server master:9092 --delete --topic test
[root@master opt]# kafka-topics.sh --bootstrap-server master:9092 --list

[root@master opt]# 
```

## 生产者与消费者

> 创建主题test

- 启动生产者：`kafka-console-producer.sh --bootstrap-server [host]:9092 --topic test`
- 启动消费者：`kafka-console-consumer.sh --bootstrap-server [host]:9092 --topic test --from-beginning`

当生产者生产消息后，消费者端会收到推送。

# Java编程

## 导入依赖

> 导入依赖时，应当注意版本！！！

```xml
        <!-- https://mvnrepository.com/artifact/org.apache.kafka/kafka -->
        <dependency>
            <groupId>org.apache.kafka</groupId>
            <artifactId>kafka_2.13</artifactId>
            <version>3.2.1</version>
        </dependency>

        <!-- https://mvnrepository.com/artifact/org.apache.kafka/kafka-clients -->
        <dependency>
            <groupId>org.apache.kafka</groupId>
            <artifactId>kafka-clients</artifactId>
            <version>3.2.1</version>
        </dependency>

```


## 生产者编程

> 创建主题java_test

```java
    @Test
    public void producer() {
        KafkaProducer<String, String> producer = null;
        try {
            Properties properties = new Properties();
            // 配置主机
            properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "master:9092");
            // 配置键序列化类型
            properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
            // 配置值序列化类型
            properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
            // 构建生产者
            producer = new KafkaProducer<>(properties);
            // 定义主题
            String topic = "java_test";
            // 发送消息
            for (int i = 0; i < 10; i++) {
                String message = "message: " + i;
                ProducerRecord<String, String> record = new ProducerRecord<>(topic, message);
                producer.send(record, (recordMetadata, e) -> {
                    if (null != e) {
                        System.out.println("发送失败！");
                    } else {
                        System.out.println("发送成功！-----" + message);
                    }
                });
            }
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            if (null != producer) {
                producer.close();
            }
        }
    }

```


## 消费者编程

```java
    @Test
    public void consumer() {
        KafkaConsumer<String, String> consumer = null;
        try {
            Properties properties = new Properties();
            // 配置主机
            properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "master:9092");
            // 配置键值的反序列化类型
            properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
            properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
            // 配置消费者组
            properties.put(ConsumerConfig.GROUP_ID_CONFIG, "group");
            //

            properties.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, "10000");
            properties.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
            properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, "true");
            properties.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, "1000");

            // 构建消费者
            consumer = new KafkaConsumer<>(properties);
            // 构建订阅主题，一个消费者可以同时定义多个主题
            String topic = "java_test";
            consumer.subscribe(Collections.singletonList(topic));
            // 消费消息
            while (true) {
                ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
                for (ConsumerRecord<String, String> record : records) {
                    System.out.println(record);
                }
            }
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            if (null != consumer) {
                consumer.close();
            }
        }
    }

```


## 测试

先启动消费者，再启动生产者。
当生产者生产消息后，消费者端会打印消息对象。

生产者的控制台输出：

```text
发送成功！-----message: 0
发送成功！-----message: 1
发送成功！-----message: 2
发送成功！-----message: 3
发送成功！-----message: 4
发送成功！-----message: 5
发送成功！-----message: 6
发送成功！-----message: 7
发送成功！-----message: 8
发送成功！-----message: 9
```

消费者的控制台输出：

```text
ConsumerRecord(topic = java_test, partition = 0, leaderEpoch = 0, offset = 20, CreateTime = 1661000768103, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = message: 0)
ConsumerRecord(topic = java_test, partition = 0, leaderEpoch = 0, offset = 21, CreateTime = 1661000768119, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = message: 1)
ConsumerRecord(topic = java_test, partition = 0, leaderEpoch = 0, offset = 22, CreateTime = 1661000768119, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = message: 2)
ConsumerRecord(topic = java_test, partition = 0, leaderEpoch = 0, offset = 23, CreateTime = 1661000768119, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = message: 3)
ConsumerRecord(topic = java_test, partition = 0, leaderEpoch = 0, offset = 24, CreateTime = 1661000768119, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = message: 4)
ConsumerRecord(topic = java_test, partition = 0, leaderEpoch = 0, offset = 25, CreateTime = 1661000768119, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = message: 5)
ConsumerRecord(topic = java_test, partition = 0, leaderEpoch = 0, offset = 26, CreateTime = 1661000768119, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = message: 6)
ConsumerRecord(topic = java_test, partition = 0, leaderEpoch = 0, offset = 27, CreateTime = 1661000768119, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = message: 7)
ConsumerRecord(topic = java_test, partition = 0, leaderEpoch = 0, offset = 28, CreateTime = 1661000768119, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = message: 8)
ConsumerRecord(topic = java_test, partition = 0, leaderEpoch = 0, offset = 29, CreateTime = 1661000768119, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = message: 9)
```