```text
Kafka简介
2022-08-14
消息队列>Kafka
https://picgo.kwcoder.club/202208/202208200937408.png
```

# 消息队列

## 什么是消息队列

消息队列（MQ，Message Queue），是一种常见的中间件。

消息队列首先是队列，队列的特征是先进先出。同时消息队列这个队列是用来传输消息的。

## 为什么要有消息队列

### 解耦合

存在系统A、B、C、D。其中A可以生产某种数据`data`。

在第一代产品中，B和C需要使用A生产的数据，则代码的依赖关系如下：

```java
public void systemA() {
    // do something to produce `data`
    systemB.send(data);
    systemC.send(data);
}

```

当产品升级后，B不再需要该数据，但是D需要，于是代码改动为：

```java
public void systemA() {
    // do something to produce `data`
    // systemB.send(data);
    systemC.send(data);
    systemD.send(data);
}

```

如果再次升级，再次更改，则需要频繁的改动系统A的代码。
同时，还存在两个问题：

- 如果在调用系统C时C挂掉了，此时还需要A的配合在能修复。 
- 如果在调用系统D时网络波动导致请求超时，那系统A该如何进一步执行？

而如果能够将系统A产生的数据推送到消息队列，而其他需要该数据的系统直接去消息队列中获取，则可以解决了系统A和其他系统之间的依赖关系，实现了解耦合。

### 异步

若有系统A、B、C、D，系统A是主要业务，B、C、D是对A业务中产生的某条数据进行处理的程序。
A产生数据data需要50ms，而B、C、D处理数据的时间均是300ms。

```java
public void systemA() {
    // do something to produce `data`
    systemB.send(data);
    systemC.send(data);
    systemD.send(data);
}

```

如果使用如上设计，则该方法将需要950ms才可以执行完，而如果系统A将数据产生后直接放入消息队列，系统B、C、D去取数据，则系统A的响应时间为50ms，整个逻辑执行的时间为300md。
利用消息中间件实现异步执行，可以提高执行效率和响应速度。

### 削峰/限流

在促销场景下，每秒会产生许多订单请求。
如果该电商系统每秒只能处理1000的请求，而用户每秒产生3000个请求，此时一定会导致系统崩溃。

而如果将订单存入消息队列，系统根据自己的执行速度去消息队列中取请求进行处理，这样就可以避免系统崩溃的情况。

## 消息队列存在的问题

- 可用性：消息队列是连接各个系统的中间件，如果消息队列挂掉了，那么必然会导致系统崩溃，因此消息队列需要保证自身的可用性。
- 数据丢失：如果在消费者拿到数据之前数据丢失了，则会导致系统不能正常运行，因此消息队列需要保证自身的数据具有可靠性。
- 如何消费：

## 消息队列的常见概念

- 生产者/发布者：将数据放入队列的角色。
- 消费者/订阅者：从队列中取数据的角色。
- 主题：队列以主题划分。

## 常见消息队列的对比

|    特性    |   ActiveMQ   |   RabbitMQ   |      RocketMQ      |       kafka        |
| :--------: | :----------: | :----------: | :----------------: | :----------------: |
| 单机吞吐量 |     万级     |     万级     |       10万级       |       10万级       |
|   时效性   |     ms级     |     us级     |        ms级        |      ms级以内      |
|   可用性   | 高(主从架构) | 高(主从架构) | 非常高(分布式架构) | 非常高(分布式架构) |


# Kafka简介

## Kafka简介

Kafka是最初由Linkedin公司开发，是一个分布式、分区的、多副本的、多订阅者，基于zookeeper协调的分布式日志系统（也可以当做MQ系统），常见可以用于web/nginx日志、访问日志，消息服务等等，Linkedin于2010年贡献给了Apache基金会并成为顶级开源项目。

其设计目标如下：

- 以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间的访问性能。 
- 高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输。 
- 支持Kafka Server间的消息分区，及分布式消费，同时保证每个partition内的消息顺序传输。 
- 同时支持离线数据处理和实时数据处理。 
- Scale out:支持在线水平扩展

## Kafka的优势

- 解耦
- 冗余（副本）：有些情况下数据处理的过程会失败，导致数据丢失。而Kafka会将数据持久化，直到它们被完全处理。
- 扩展性：可以在集群不停止的情况下对集群进行扩展。
- 灵活性：在访问里那个激增的特殊情况下，Kafka的关键组件会顶住突发流量的压力而不会导致超负荷的情况。
- 可恢复性：当一部分组件挂掉后不影响整个系统。
- 顺序保证：Kafka可以保证一个Partition内的消息有序。
- 缓冲：利用缓冲可以提高效率。
- 异步通信：Kafka允许消息大规模堆积。

## Kafka的应用场景

主要用于不同系统间的数据交流和传递，在企业解决方案、金融支付、电信、电子商务、社交、即时通信、视频、物联网、车联网等众多领域都有广泛应用。

# Kafka的常见术语

![1-1kafka](https://picgo.kwcoder.club/202208/202208202236193.png)



## broker

Kafka 集群包含一个或多个服务器，服务器节点称为broker。

broker存储topic的数据。如果某topic有N个partition，集群有N个broker，那么每个broker存储该topic的一个partition。

如果某topic有N个partition，集群有(N+M)个broker，那么其中有N个broker存储该topic的一个partition，剩下的M个broker不存储该topic的partition数据。

如果某topic有N个partition，集群中broker数目少于N个，那么一个broker存储该topic的一个或多个partition。在实际生产环境中，尽量避免这种情况的发生，这种情况容易导致Kafka集群数据不均衡。

## topic

每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处），类似于数据库的表名。

## Partition

topic中的数据分割为一个或多个partition。每个topic至少有一个partition。

每个partition中的数据使用多个segment文件存储。partition中的数据是有序的，不同partition间的数据丢失了数据的顺序。
如果topic有多个partition，消费数据时就不能保证数据的顺序。在需要严格保证消息的消费顺序的场景下，需要将partition数目设为1。

## leader和follower

每个partition有多个副本，其中有且仅有一个作为Leader，Leader是当前负责数据的读写的partition。

Follower跟随Leader，所有写请求都通过Leader路由，数据变更会广播给所有Follower，Follower与Leader保持数据同步。如果Leader失效，则从Follower中选举出一个新的Leader。当Follower与Leader挂掉、卡住或者同步太慢，leader会把这个follower从ISR(in sync replicas)列表中删除，重新创建一个Follower。

## Producer、Consumer、Consumer Group

分别是生产者、消费者、消费者组。

每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。