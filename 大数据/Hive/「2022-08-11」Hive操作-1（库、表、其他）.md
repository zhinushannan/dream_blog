```text
Hive操作 - 1（库、表、其他）
大数据>Hive
2022-08-11
https://picgo.kwcoder.club/202208/202208161604333.png
```

# 数据库与表操作

## 数据库的创建、切换与删除

```sql
use default;

drop database if exists stu;

create database if not exists stu;

use stu;

drop database if exists stu;

```

## 表的创建、修改与删除

```sql
drop database if exists stu;

create database if not exists stu;

use stu;

create table if not exists student
(
    name STRING,
    age  int
);

```



![5-1创建表](https://picgo.kwcoder.club/202208/202208171035772.png)



```sql
-- 添加列

alter table student
    add columns (score int);

-- 修改列的数据类型

alter table student
    change age age bigint;

```



![5-2列的修改与添加](https://picgo.kwcoder.club/202208/202208171036138.png)



```sql
alter table student
    replace columns (
        name STRING,
        age bigint
        );

-- 重命名表

alter table student
    rename to mystudent;

-- 显示表的扩展信息

describe extended mystudent;

```



![5-3列的删除](https://picgo.kwcoder.club/202208/202208171036290.png)



表的扩展信息：

| col_name                   | data_type                                                    | comment |
| :------------------------- | :----------------------------------------------------------- | :------ |
| name                       | string                                                       |         |
| age                        | bigint                                                       |         |
|                            | null                                                         | null    |
| Detailed Table Information | Table\(tableName:mystudent, dbName:stu, owner:anonymous, createTime:1660698367, lastAccessTime:0, retention:0, sd:StorageDescriptor\(cols:\[FieldSchema\(name:name, type:string, comment:null\), FieldSchema\(name:age, type:bigint, comment:null\)\], location:hdfs://master:9000/hive/warehouse/stu.db/mystudent, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo\(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}\), bucketCols:\[\], sortCols:\[\], parameters:{}, skewedInfo:SkewedInfo\(skewedColNames:\[\], skewedColValues:\[\], skewedColValueLocationMaps:{}\), storedAsSubDirectories:false\), partitionKeys:\[\], parameters:{last\_modified\_time=1660698389, totalSize=0, numRows=0, rawDataSize=0, COLUMN\_STATS\_ACCURATE={\\"BASIC\_STATS\\":\\"true\\",\\"COLUMN\_STATS\\":{\\"age\\":\\"true\\",\\"name\\":\\"true\\"}}, numFiles=0, transient\_lastDdlTime=1660698389, bucketing\_version=2, last\_modified\_by=anonymous}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED\_TABLE, rewriteEnabled:false, catName:hive, ownerType:USER\) |         |


```sql
-- 删除表

drop table mystudent;

```

## 数据的插入

```sql
drop database if exists stu;

create database if not exists stu;

create table if not exists student
(
    name STRING,
    age  int
);

-- 插入单条数据

insert into student
values ('xiaoming', 18);

-- 插入多条数据

insert into student
values ('zhangsan', 19),
       ('lisi', 20);

insert into student
select 'wangwu', 21
union
select 'hanmeimei', 22;


select name, age
from student;

```

| name      | age  |
| :-------- | :--- |
| xiaoming  | 18   |
| zhangsan  | 19   |
| lisi      | 20   |
| hanmeimei | 22   |
| wangwu    | 21   |

> 在执行insert语句时，可能会提示错误，但是实际上是插入成功的。因为hive是基于HDFS的，不擅长增删改。

# 数据类型

## 数据类型

hive存在基本数据类型和符合数据类型。

基本数据类型：

- 整型：tinyint、smallint、int、bigint
- 浮点型：float、double
- 十进制：decimal
- 布尔：boolean
- 二进制：binary
- 字符串：char、varchar、string
- 日期与时间：date、timestamp

符合数据类型：

- 数组：array
- 集合：map
- 结构体：struct

## 数组类型

创建表：

```sql
create table if not exists student
(
    name   string,
    age    int,
    scores array<double>
)
-- 行格式以 , 分隔字段
    row format delimited fields terminated by ','
-- 元素以 : 分割
        collection items terminated by ':'
--  以 textfile 文件格式存储
    stored as textfile;

```

创建数据（存放在服务器中的`/root/student.txt`中）：

```text
zhangsan,18,55:77:60
xiaoming,19,94:76:88
```

加载并查询数据：

```sql
load data local inpath '/root/student.txt' overwrite into table student;

select *
from student;

select name, age, scores[0], scores[1], scores[2]
from student;

select name, age, scores[0] as chinese, scores[1] as math, scores[2] as english
from student;

```

三次查询的结果分别为：


|   name   | age  |      scores      |
| :------: | :--: | :--------------: |
| zhangsan |  18  | [55.0,77.0,60.0] |
| xiaoming |  19  | [94.0,76.0,88.0] |




|   name   | age  | _c2  | _c3  | _c4  |
| :------: | :--: | :--: | :--: | :--: |
| zhangsan |  18  |  55  |  77  |  60  |
| xiaoming |  19  |  94  |  76  |  88  |




|   name   | age  | chinese | math | english |
| :------: | :--: | :-----: | :--: | :-----: |
| zhangsan |  18  |   55    |  77  |   60    |
| xiaoming |  19  |   94    |  76  |   88    |


## 集合类型

创建数据（存放在服务器中的`/root/student_map.txt`中）：

```text
zhangsan,18,chinese_55:math_77:english_60
xiaoming,19,chinese_94:math_76:english_88
```

```sql

use default;

drop table if exists student_map;

create table if not exists student_map
(
    name   string,
    age    int,
    scores map<string, double>
)
-- 行以 , 分割字段
    row format delimited fields terminated by ','
-- 元素以 : 分割
        collection items terminated by ':'
-- 集合以 _ 分割
        map keys terminated by '_'
-- 以 textfile 文件存储
    stored as textfile
;

load data local inpath '/root/student_map.txt' overwrite into table student_map;

select name, age, scores['chinese'] as chinese, scores['math'] as math, scores['english'] as english
from student_map;

```



|   name   | age  | chinese | math | english |
| :------: | :--: | :-----: | :--: | :-----: |
| zhangsan |  18  |   55    |  77  |   60    |
| xiaoming |  19  |   94    |  76  |   88    |

## 结构体类型

创建数据（存放在服务器中的`/root/student_struct.txt`中）：

```text
zhangsan,18,chinese:55:math:60
xiaoming,19,chinese:94
```

```sql
use default;

drop table if exists student_struct;

create table if not exists student_struct
(
    name    string,
    age     int,
    subject struct<name:string, score:double>
)
    row format delimited fields terminated by ','
    collection items terminated by ':'
    stored as textfile
;

load data local inpath '/root/student_struct.txt' into table student_struct;

select * from student_struct;

select name, age, subject.name, subject.score from student_struct;

```

两次查询的结果分别为：

|   name   | age  |             subject             |
| :------: | :--: | :-----------------------------: |
| zhangsan |  18  | {"name":"chinese","score":55.0} |
| xiaoming |  19  | {"name":"chinese","score":94.0} |


|   name   | age  |  name   | score |
| :------: | :--: | :-----: | :---: |
| zhangsan |  18  | chinese |  55   |
| xiaoming |  19  | chinese |  94   |


> 针对集合、map、结构体的查询可以使用array[0]>50、map['key']>50、struct.field>50等方式。



# `load`命令

load命令用于加载文件，可以加载本地和HDFS文件。

加载本地文件：`load data local inpath [本地路径] overwrite into table [table_name]`
加载HDFS文件：`load data inpath [HDFS路径] overwrite into table [table_name]`

> 1、从本地加载文件是上传，加载完成后本地文件依然存在，而加载HDFS文件是移动文件，加载完成后原文件不存在。
> 2、overwrite参数是可选参数，如果使用该参数，在加载文件之前会清空原表。