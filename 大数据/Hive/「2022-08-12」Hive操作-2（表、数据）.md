```text
Hive操作 - 2（表、数据）
大数据>Hive
2022-08-12
https://picgo.kwcoder.club/202208/202208161604333.png
```

# 表的扩展操作

## 通过查询创建表

```sql
-- 拷贝表结构和数据

create table if not exists student_cp1
as
select name, scores['chinese'], scores['math'], scores['english']
from student_map;

select *
from student_cp1;

-- 只拷贝表结构

create table if not exists student_cp2
as
select name, scores['chinese'] as chinese, scores['math'] as math, scores['english'] as english
from student_map
where 1 = 0;

select * 
from student_cp2;

```

查询结果：

|   name   | _c1  | _c2  | _c3  |
| :------: | :--: | :--: | :--: |
| zhangsan |  55  |  77  |  60  |
| xiaoming |  94  |  76  |  88  |


| name | chinese | math | english |
| :--: | :-----: | :--: | :-----: |
|      |         |      |         |

## 创建表（主外键、默认值等）

```sql
create table if not exists emp
(
    id   int    not null,
    name string not null,
    sex  string default 'f',
    pid  int    not null,
    -- disable novalidate  关闭约束，删除索引，标识可以对约束列的数据进行修改等操作
    primary key (id) disable novalidate,
    constraint fk_pid_id foreign key (pid) references emp (id) disable novalidate
);

```



![6-1创建表](https://picgo.kwcoder.club/202208/202208172156896.png)



## 事务表

内部表可以成为事务表，外部表不可以。

```sql
create table if not exists student_tran
(
    id   int,
    name string
) stored as orc
    tblproperties (
        'transactional' = 'true',
        'transactional_properties' = 'default'
        );

```

## 外部表

内部表的数据存储在`/hive/warehouse/mydb.db/[db_name]`中，由Hive管理。
外部表的数据存储在HDFS中，Hive仅指向该文件的一个引用。

当外部表删除时，数据依然存在，即原文件。
当内部表删除时，数据也被删除。


```sql
create external table if not exists emp (
    id int,
    name string
) row format delimited fields terminated by ','
location '/demo';

```

## 分区表

分区表和桶表都可以提高查询效率，分区表是粗粒度、桶表是细粒度。

分区表将数据拆分为N个分区，每个数据存储在特定的分区中。
在HDFS的表现形式上，一个分区就是一个目录。

```sql
create table if not exists sales
(
    userid int,
    amount double
) partitioned by (region string)
    row format delimited fields terminated by ',';

insert into sales partition (region = 'nj')
values (1001, 88.88),
       (1002, 99.99);

insert into sales partition (region = 'bj')
values (1003, 66.66);

select *
from sales;

-- 查询1：销售小于70的数据
select userid, amount, region
from sales
where amount < 70;

-- 查询2：销售地区为北京的数据
select userid, amount, region
from sales
where region = 'bj';

```

创建的表结构：



![6-2分区表](https://picgo.kwcoder.club/202208/202208172157718.png)



添加数据后，在HDFS的体现如下：



![6-3分区表hdfs](https://picgo.kwcoder.club/202208/202208172157020.png)



查询的结果：

| userid | amount | region |
| :----: | :----: | :----: |
|  1003  | 66.66  |   bj   |
|  1001  | 88.88  |   nj   |
|  1002  | 99.99  |   nj   |


| userid | amount | region |
| :----: | :----: | :----: |
|  1003  | 66.66  |   bj   |


| userid | amount | region |
| :----: | :----: | :----: |
|  1003  | 66.66  |   bj   |


> 如果需要加载数据，则一个文件内的所有数据意味着属于同一分区，且提供的数据中不能有分区列。


增加分区：

```sql
alter table sales
    add partition (region = 'sh');

```

增加分区后，在HDFS中会多出对应的分区文件夹。

删除分区：

```sql
alter table sales drop
    if exists partition (region= 'nj');

```

删除分区后，在HDFS中对应的文件夹会被删除，同时Hive表中对应的数据也会被删除。

## 桶表

桶表相较于分区表来说，拥有更为细粒度的数据范围划分。
桶是对列值进行哈希，然后除以桶的个数求余，决定该条数据存放在哪个桶中。
在桶表中，一个桶就是一个文件。

### 桶表

```sql

create database if not exists mydb;
use mydb;
-- 开启分桶
set hive.enforce.bucketing = true;
-- 设置桶的数量
set mapreduce.job.reduces = 3;
-- 创建桶表
create table if not exists users
(
    uid  int,
    name string
) 
-- 根据uid分桶
clustered by (uid) into 3 buckets
    row format delimited fields terminated by ',';

insert into users
values (1, 'zhangsan1'),
       (2, 'zhangsan2'),
       (3, 'zhangsan3'),
       (4, 'zhangsan4'),
       (5, 'zhangsan5'),
       (6, 'zhangsan6');

```



![6-4桶表](https://picgo.kwcoder.club/202208/202208172157693.png)



### 排序桶表

```sql
create database if not exists mydb;
use mydb;
-- 开启分桶
set hive.enforce.bucketing = true;
-- 设置桶的数量
set mapreduce.job.reduces = 3;
-- 创建桶表
create table if not exists users_sort
(
    uid  int,
    name string
) clustered by (uid) sorted by (uid desc) into 3 buckets
    row format delimited fields terminated by ',';

insert into users_sort
values (1, 'zhangsan1'),
       (2, 'zhangsan2'),
       (3, 'zhangsan3'),
       (4, 'zhangsan4'),
       (5, 'zhangsan5'),
       (6, 'zhangsan6');

```

# 其他命令

```sql
show databases;
show tables;
show partitions db_name.table_name;
show functions;
desc db_name.table_name;
desc extended db_name.table_name;
desc formatted db_name.table_name;

```

# 数据的增删改与导出

## 插入数据

```sql
drop table if exists emp;

create table if not exists emp
(
    id   int    not null,
    name string not null,
    sex  string default 'f',
    pid  int    not null,
    -- disable novalidate  关闭约束，删除索引，标识可以对约束列的数据进行修改等操作
    primary key (id) disable novalidate,
    constraint fk_pid_id foreign key (pid) references emp (id) disable novalidate
);

insert into emp
values (1, 'zhangsan', 'f', 0),
       (2, 'lisi', 'f', 0),
       (3, 'zhangfei', 'f', 1);

select *
from emp;

```

|  id  |   name   | sex  | pid  |
| :--: | :------: | :--: | :--: |
|  1   | zhangsan |  f   |  0   |
|  2   |   lisi   |  f   |  0   |
|  3   | zhangfei |  f   |  1   |



## 修改与删除数据

Hive不支持修改和删除数据，但是可以在事务表中通过先查询再覆盖的方式模拟修改和删除。但执行效率极低，非常不推荐执行该操作。


清空数据表（外部表无效）：
```sql

truncate table  emp;

```


导出数据：
- 一次导出一个文件
    - insert  local directory   ‘ … ’   select 列名列表   from 表名 ;
    - insert directory   ‘ … ’     select 列名列表   from 表名 ;
    - insert overwrite  local   directory   ‘ … ’     select 列名列表   from 表名 ;
    - insert overwrite   directory     ‘ … ’   select 列名列表   from 表名 ;
- 一次导出多个文件
    - from 表名
    - insert  local directory   ‘ … ’   select 列名列表
    - insert directory   ‘ … ’     select 列名列表