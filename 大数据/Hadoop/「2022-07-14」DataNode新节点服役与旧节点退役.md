```text
DataNode新节点服役与旧节点退役
大数据>Hadoop
2022-07-14
https://picgo.kwcoder.club/202206/202206261620161.png
```



在阅读此篇之前，应当先阅读[基于CentOS7镜像和数据挂载卷实现Docker搭建Hadoop集群](/p/20220626/)

# 服役与退役

Hadoop集群中管理员经常需要向集群中添加节点，或从集群中移除节点。
例如为了扩大存储容量或其他业务需求，需要上线一个DataNode的新节点，这被称为服役（新节点上线）。
相反的，在某些节点出现反常（如故障率过高或者性能过于低下）或其他业务需求，需要下线节点，而且保证不关闭集群和不损害集群中某一天机器的数据节点数据块丢失，这被称为退役（旧节点下线）。

# 新节点服役

## 准备新机器

具体操作略，步骤如下：

1. 配置JDK和Hadoop环境变量（可以直接从master机器上远程分发）
2. 修改该节点的`/etc/hosts`文件，添加其他节点的IP和域名 
3. 修改其他节点的`/etc/hosts`文件，添加该新节点的IP和域名
4. 使该节点可以与其他节点相互之间免密登录

## 添加和修改配置文件

新建`datanode.include`和`nodemanager.include`，分别用来指定现役datanode节点和nodemanager节点所在的主机，位置任意，我新建在`$HADOOP_HOME/etc/hadoop/`下。

我新增的节点域名为`slave3`，现在的需求是在`slave3`主机上新增datanode和nodemanager，所以我在这两个文件里需要将`slave3`添加这两个文件中。
但是由于这两个文件是用来指定现役的节点，因此之前的节点也应该添加进去。

```text
slave1
slave2
slave3
```

编辑`$HADOOP_HOME/etc/hadoop/hdfs-site.xml`文件，添加（注意，其中的`value`的值应当根据自己的配置来）：

```xml
<property>
    <!-- 指定一个文件的完整路径,没有指定，说明说有节点都可连接 -->		
    <name>dfs.hosts</name>
    <value>/opt/module/hadoop-3.3.1/etc/hadoop/datanode.include</value>
</property>
```

编辑`$HADOOP_HOME/etc/hadoop/yarn-site.xml`文件，添加（注意，其中的`value`的值应当根据自己的配置来）：

```xml
<property>
    <!--配置nodemanager -->
    <name>yarn.resourcemanager.nodes.include-path</name>
    <value>/opt/module/hadoop-3.3.1/etc/hadoop/nodemanager.include</value>
</property>
```

## 刷新hdfs和yarn



![1现有datanode](https://picgo.kwcoder.club/202206/202207170126498.png)



在NameNode节点上执行`hdfs dfsadmin -refreshNode`，在`ResourceManagerNode`节点上执行`yarn rmadmin -refreshNodes`。

进入`slave3`，执行`hadoop-daemon.sh start datanode`和`yarn-daemon.sh start nodemanager`启动`DataNode`和`NodeManager`。



![2上线后datanode](https://picgo.kwcoder.club/202206/202207170127115.png)



回到`master`主机，执行`start-balancer.sh`平衡节点。
上传文件测试，该节点正常接收分块：



![3接收分块](https://picgo.kwcoder.club/202206/202207170127554.png)



# 旧节点退役

## 添加和修改配置文件


新建`datanode.exclude`和`nodemanager.exclude`，分别用来指定现役datanode节点和nodemanager节点所在的主机，位置任意，我新建在`$HADOOP_HOME/etc/hadoop/`下。

我退役的节点域名为`slave3`，所以要在这两个文件里需要将`slave3`添加这两个文件中。
注意：此时不要把`include`中的`slave3`删除，否则将无法正常迁移副本。

编辑`$HADOOP_HOME/etc/hadoop/hdfs-site.xml`文件，添加（注意，其中的`value`的值应当根据自己的配置来）：

```xml
<property>
    <name>dfs.hosts.exclude</name>
    <value>/opt/module/hadoop-3.3.1/etc/hadoop/datanode.include</value>
</property>
```

编辑`$HADOOP_HOME/etc/hadoop/yarn-site.xml`文件，添加（注意，其中的`value`的值应当根据自己的配置来）：

```xml
<property>
    <name>yarn.resourcemanager.nodes.exclude-path</name>
    <value>/opt/module/hadoop-3.3.1/etc/hadoop/nodemanager.include</value>
</property>
```

## 刷新hdfs和yarn和平衡资源

在master上执行

```shell
hdfs dfsadmin -refreshNodes
yarn rmadmin -refreshNodes
start-balancer.sh
```

执行之后会自动根据负载均衡的原则迁移副本：



![4节点退役](https://picgo.kwcoder.club/202206/202207170127672.png)



等待前面的标变为黄色(`Decommissioned`)时，即退役完成，此时方可进入`slave3`执行`hadoop-daemon.sh stop datanode`和`yarn-daemon.sh stop nodemanager`关闭`DataNode`和`NodeManager`。



![5退役完成](https://picgo.kwcoder.club/202206/202207170127590.png)



然后将`include`中的`slave3`删除，再次刷新hdfs和yarn

```shell
hdfs dfsadmin -refreshNodes
yarn rmadmin -refreshNodes
```

